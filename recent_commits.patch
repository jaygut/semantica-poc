commit 828c7024a85bf3eb8ab6a2f419ded520abc365c2
Author: Jay Gut <jaygut@example.com>
Date:   Sat Feb 21 12:08:32 2026 -0500

    feat(ui): split quick queries into Site Intelligence and Prospective Scenarios sections
    
    The flat QUICK QUERIES grid is replaced by two labelled sections:
    
    - SITE INTELLIGENCE (6 buttons, blue diamond accent): knowledge-graph
      queries covering valuation, evidence, NEOLI, comparison, risks,
      and blue carbon concept explanation.
    
    - PROSPECTIVE SCENARIOS (4 buttons, teal arrow accent): v6 scenario
      engine queries - counterfactual, SSP2-4.5 climate, blue carbon
      revenue, and tipping point proximity.
    
    Each section has a distinct header style and border colour to reinforce
    the architectural distinction between historical intelligence (graph
    retrieval) and forward-looking computation (scenario engine).
    
    _build_quick_queries() now returns (historical, scenario) tuple instead
    of a flat list. Button keys updated to v4_hist_N / v4_scen_N.
    
    Co-Authored-By: Claude Sonnet 4.6 <noreply@anthropic.com>

diff --git a/investor_demo/components/v4/graphrag_chat.py b/investor_demo/components/v4/graphrag_chat.py
index ae72631..7c1280d 100644
--- a/investor_demo/components/v4/graphrag_chat.py
+++ b/investor_demo/components/v4/graphrag_chat.py
@@ -155,21 +155,45 @@ def render_graphrag_chat(
     with st.expander("How confidence is computed (full transparency)", expanded=False):
         st.markdown(_confidence_methodology_markdown())
 
-    # Quick query buttons
-    quick_queries = _build_quick_queries(site_short, context_name)
+    # Quick query buttons — two labelled sections
+    historical_queries, scenario_queries = _build_quick_queries(site_short, context_name)
+
+    _SECTION_HEADER = (
+        "display:flex;align-items:center;gap:10px;"
+        "font-size:13px;font-weight:700;text-transform:uppercase;letter-spacing:1.2px;"
+        "margin:16px 0 10px 0;padding-bottom:6px;"
+        "border-bottom:1px solid"
+    )
+    # Site intelligence header (slate-blue accent)
+    st.markdown(
+        f'<div style="{_SECTION_HEADER} #1E3A5F;">'
+        '<span style="color:#60A5FA">&#9670;</span>'
+        '<span style="color:#94A3B8">Site Intelligence</span>'
+        "</div>",
+        unsafe_allow_html=True,
+    )
+    for row_start in range(0, len(historical_queries), 2):
+        row = st.columns(2)
+        for col_idx, q in enumerate(historical_queries[row_start: row_start + 2]):
+            with row[col_idx]:
+                if st.button(q, key=f"v4_hist_{row_start + col_idx}", use_container_width=True):
+                    _submit_query(client, q, mode)
+
+    # Prospective scenarios header (teal accent)
     st.markdown(
-        '<div style="font-size:15px;font-weight:600;color:#94A3B8;'
-        'margin-bottom:10px;text-transform:uppercase;letter-spacing:1px">'
-        "Quick queries</div>",
+        f'<div style="{_SECTION_HEADER} #0D3D3D;margin-top:20px;">'
+        '<span style="color:#2DD4BF">&#9654;</span>'
+        '<span style="color:#5EEAD4">Prospective Scenarios</span>'
+        '<span style="color:#475569;font-size:11px;font-weight:400;'
+        'text-transform:none;letter-spacing:0">- powered by v6 Scenario Intelligence</span>'
+        "</div>",
         unsafe_allow_html=True,
     )
-    grid_cols = 2
-    for row_start in range(0, len(quick_queries), grid_cols):
-        row = st.columns(grid_cols)
-        for col_idx, q in enumerate(quick_queries[row_start: row_start + grid_cols]):
-            button_idx = row_start + col_idx
+    for row_start in range(0, len(scenario_queries), 2):
+        row = st.columns(2)
+        for col_idx, q in enumerate(scenario_queries[row_start: row_start + 2]):
             with row[col_idx]:
-                if st.button(q, key=f"v4_quick_{button_idx}", use_container_width=True):
+                if st.button(q, key=f"v4_scen_{row_start + col_idx}", use_container_width=True):
                     _submit_query(client, q, mode)
 
     with st.form(key="v4_query_form", clear_on_submit=True):
@@ -191,23 +215,14 @@ def render_graphrag_chat(
 # ---------------------------------------------------------------------------
 
 
-def _build_quick_queries(site_short: str, full_name: str) -> list[str]:
-    """Return 10 quick-query strings: 6 existing + 4 scenario queries."""
-    defaults = [
-        f"What is {site_short} worth?",
-        "What evidence supports the valuation?",
-        "How is NEOLI calculated?",
-        "Compare sites in the portfolio",
-        f"What are the risks for {site_short}?",
-        "How does blue carbon sequestration work?",
-        # v6 scenario quick-queries
-        f"What would {site_short} be worth without protection?",
-        f"What happens to {site_short} under SSP2-4.5 by 2050?",
-        f"What blue carbon revenue could {site_short} generate at $45/tCO2?",
-        f"How close is {site_short} to a tipping point?",
-    ]
+def _build_quick_queries(
+    site_short: str, full_name: str
+) -> tuple[list[str], list[str]]:
+    """Return (historical_queries, scenario_queries) as two separate lists.
 
-    # v6 scenario quick-queries (always appended)
+    historical_queries: 6 site-intelligence questions (knowledge graph)
+    scenario_queries:   4 prospective scenario questions (v6 engine)
+    """
     scenario_queries = [
         f"What would {site_short} be worth without protection?",
         f"What happens to {site_short} under SSP2-4.5 by 2050?",
@@ -215,55 +230,67 @@ def _build_quick_queries(site_short: str, full_name: str) -> list[str]:
         f"How close is {site_short} to a tipping point?",
     ]
 
-    # Try to load from case study JSON first
+    default_historical = [
+        f"What is {site_short} worth?",
+        "What evidence supports the valuation?",
+        "How is NEOLI calculated?",
+        "Compare sites in the portfolio",
+        f"What are the risks for {site_short}?",
+        "How does blue carbon sequestration work?",
+    ]
+
+    # Try to load custom historical queries from case study JSON
     from investor_demo.components.v4.shared import get_site_data
     site_data = get_site_data(full_name)
     if site_data:
         custom = site_data.get("demo_value", {}).get("quick_queries", [])
         if custom:
-            return (custom + scenario_queries)[:10]
+            return custom[:6], scenario_queries
 
-    # Fallback to hardcoded logic (legacy safety net)
+    # Fallback to site-specific hardcoded historical queries
     lower_name = full_name.lower()
+    bc_concept = "How does blue carbon sequestration work?"
 
     if "galapagos" in lower_name:
-        return [
+        historical = [
             "How does El Nino impact Galapagos?",
             "What is the value of hammerhead shark tourism?",
             "How does the NEOLI score explain recovery?",
             "Compare Galapagos to Cabo Pulmo",
             "What conflict exists with industrial fishing?",
-            defaults[5],
-        ] + scenario_queries
+            bc_concept,
+        ]
     elif "cabo pulmo" in lower_name:
-        return [
+        historical = [
             "What drove the 463% biomass recovery?",
             "What is the total ecosystem service value?",
             "How did community enforcement help?",
             "Compare to other Gulf of California sites",
             "What are the top 3 species recovering?",
-            defaults[5],
-        ] + scenario_queries
+            bc_concept,
+        ]
     elif "ningaloo" in lower_name:
-        return [
+        historical = [
             "What is the value of whale shark tourism?",
             "How does the Leeuwin Current affect biodiversity?",
             "What evidence supports the resilience rating?",
             "Compare tourism revenue to fisheries",
             "What are the threats from oil and gas?",
-            defaults[5],
-        ] + scenario_queries
+            bc_concept,
+        ]
     elif "belize" in lower_name:
-        return [
+        historical = [
             "What is the value of storm protection?",
             "How does coral bleaching risk affect value?",
             "What is the impact of mangrove loss?",
             "Compare coastal protection to tourism value",
             "What is the status of the barrier reef?",
-            defaults[5],
-        ] + scenario_queries
+            bc_concept,
+        ]
+    else:
+        historical = default_historical
 
-    return defaults
+    return historical, scenario_queries
 
 
 # ---------------------------------------------------------------------------

commit 50ed6f2a3ccda76ec3ab1e6c54aaf008336680d7
Author: Jay Gut <jaygut@example.com>
Date:   Fri Feb 20 09:11:02 2026 -0500

    fix(scenario): classifier and rendering fixes for blue carbon revenue queries
    
    - classifier.py: add blue carbon revenue patterns to scenario_analysis
      triggers and strong-signal tie-breaker (fixes misrouting to site_valuation)
    - graphrag_chat.py: make KPI strip type-aware (market shows revenue,
      tipping_point skips strip, counterfactual/climate show ESV delta)
    - models.py: add annual_revenue_usd and revenue_range to QueryResponse
    - routes/query.py: populate new fields from compute_blue_carbon_revenue()
    - test_phase_a_api.py: add regression test for blue carbon button routing
    
    1145 passed, 0 failures
    
    Co-Authored-By: Claude Sonnet 4.6 <noreply@anthropic.com>

diff --git a/investor_demo/components/v4/graphrag_chat.py b/investor_demo/components/v4/graphrag_chat.py
index aa76d58..ae72631 100644
--- a/investor_demo/components/v4/graphrag_chat.py
+++ b/investor_demo/components/v4/graphrag_chat.py
@@ -562,15 +562,31 @@ def render_scenario_response(response: dict, container: Any = None) -> None:
     if response.get("scenario_request") is None:
         return  # Not a scenario response; use existing render path
 
-    # KPI strip: Baseline | Scenario | Delta
-    col1, col2, col3 = target.columns(3)
-    baseline_esv = response.get("baseline_case", {}).get("total_esv_usd", 0)
-    scenario_esv = response.get("scenario_case", {}).get("total_esv_usd", 0)
-    delta_pct = (scenario_esv - baseline_esv) / baseline_esv * 100 if baseline_esv else 0
-
-    col1.metric("Baseline ESV", f"${baseline_esv / 1e6:.1f}M")
-    col2.metric("Scenario ESV", f"${scenario_esv / 1e6:.1f}M")
-    col3.metric("Delta", f"{delta_pct:+.1f}%", delta=f"${abs(scenario_esv - baseline_esv) / 1e6:.1f}M")
+    # KPI strip: type-dependent metrics
+    scenario_req = response.get("scenario_request") or {}
+    scenario_type = scenario_req.get("scenario_type", "counterfactual")
+
+    if scenario_type == "market":
+        # Blue carbon revenue: show annual revenue and range
+        annual_rev = response.get("annual_revenue_usd", 0)
+        rev_range = response.get("revenue_range", {})
+        col1, col2, col3 = target.columns(3)
+        col1.metric("Annual Revenue", f"${annual_rev / 1e6:.2f}M/yr" if annual_rev else "See answer")
+        col2.metric("Range Low", f"${rev_range.get('low', 0) / 1e6:.2f}M" if rev_range else "-")
+        col3.metric("Range High", f"${rev_range.get('high', 0) / 1e6:.2f}M" if rev_range else "-")
+    elif scenario_type == "tipping_point":
+        # Tipping point: no ESV delta — skip KPI strip, info is in the answer text
+        pass
+    else:
+        # Counterfactual / climate / intervention: show ESV delta
+        baseline_esv = response.get("baseline_case", {}).get("total_esv_usd", 0)
+        scenario_esv = response.get("scenario_case", {}).get("total_esv_usd", 0)
+        if baseline_esv or scenario_esv:
+            delta_pct = (scenario_esv - baseline_esv) / baseline_esv * 100 if baseline_esv else 0
+            col1, col2, col3 = target.columns(3)
+            col1.metric("Baseline ESV", f"${baseline_esv / 1e6:.1f}M")
+            col2.metric("Scenario ESV", f"${scenario_esv / 1e6:.1f}M")
+            col3.metric("Delta", f"{delta_pct:+.1f}%", delta=f"${abs(scenario_esv - baseline_esv) / 1e6:.1f}M")
 
     # Tipping point badge (if present)
     if response.get("tipping_point_proximity"):
diff --git a/maris/api/models.py b/maris/api/models.py
index 877492a..ca1efdf 100644
--- a/maris/api/models.py
+++ b/maris/api/models.py
@@ -79,6 +79,9 @@ class QueryResponse(BaseModel):
     provenance_warnings: list[str] = []
     provenance_risk: str = "high"
     query_metadata: QueryMetadata = QueryMetadata()
+    scenario_request: dict | None = None  # populated for scenario_analysis responses
+    annual_revenue_usd: float | None = None  # populated for market (blue carbon) scenarios
+    revenue_range: dict | None = None        # {"low": float, "high": float}
 
 
 # ---------------------------------------------------------------------------
diff --git a/maris/api/routes/query.py b/maris/api/routes/query.py
index 6e3d150..08a4e7d 100644
--- a/maris/api/routes/query.py
+++ b/maris/api/routes/query.py
@@ -501,6 +501,8 @@ def query(request: QueryRequest):
                         "axioms_used": ["BA-007", "BA-017"],
                         "provenance_risk": "medium",
                         "scenario_request": scenario_req.model_dump(),
+                        "annual_revenue_usd": rev["annual_revenue_usd"],
+                        "revenue_range": rev["annual_revenue_range"],
                     }
         else:
             result = {
@@ -536,6 +538,9 @@ def query(request: QueryRequest):
             evidence_completeness_score=0.0,
             provenance_warnings=result.get("provenance_warnings", []),
             provenance_risk=result.get("provenance_risk", "high"),
+            scenario_request=result.get("scenario_request"),
+            annual_revenue_usd=result.get("annual_revenue_usd"),
+            revenue_range=result.get("revenue_range"),
             query_metadata=QueryMetadata(
                 category="scenario_analysis",
                 classification_confidence=classification.get("confidence", 0.0),
diff --git a/maris/query/classifier.py b/maris/query/classifier.py
index 4b58b95..45f3b94 100644
--- a/maris/query/classifier.py
+++ b/maris/query/classifier.py
@@ -59,6 +59,8 @@ _KEYWORD_RULES: list[tuple[str, list[str]]] = [
         r"\bwithout\s+protection\b",
         r"\brestore|restoration\b",
         r"\bcarbon\s+price.{0,20}(?:at|\$|\d)",
+        r"\bblue\s+carbon\s+revenue\b",
+        r"\bcarbon\s+revenue.{0,30}(?:\$|\d)",
         r"\btipping\s+point\b",
         r"\bstress\s+test\b",
         r"\bnature\s+var\b",
@@ -279,6 +281,8 @@ class QueryClassifier:
                 r"|\bstress\s+test\b"
                 r"|\bnature\s+var\b"
                 r"|\bcarbon\s+price.{0,20}(?:at|\$|\d)"
+                r"|\bblue\s+carbon\s+revenue\b"
+                r"|\bcarbon\s+revenue.{0,30}(?:\$|\d)"
                 r"|\binvest\s+\$?\d"
                 r"|\bif\s+(?:we|you|they).{0,20}(?:invest|restore|protect|stop)\b"
                 r"|\bhow\s+(?:close|far).{0,30}(?:threshold|regime|tipping)",
diff --git a/tests/scenario/test_phase_a_api.py b/tests/scenario/test_phase_a_api.py
index dc5a269..138acb7 100644
--- a/tests/scenario/test_phase_a_api.py
+++ b/tests/scenario/test_phase_a_api.py
@@ -53,6 +53,13 @@ class TestScenarioClassifier:
         )
         assert result["category"] == "scenario_analysis"
 
+    def test_scenario_classifier_blue_carbon_revenue_button(self, classifier):
+        """Quick-query button for blue carbon uses 'revenue' not 'price' - must still classify."""
+        result = classifier.classify(
+            "What blue carbon revenue could Sundarbans Reserve generate at $45/tCO2?"
+        )
+        assert result["category"] == "scenario_analysis"
+
     def test_scenario_classifier_ssp_question(self, classifier):
         result = classifier.classify(
             "What happens to Belize under SSP2-4.5 by 2050?"

commit e7670fcfcb858029aaa40b92e190c60d50d04239
Author: Jay Gut <jaygut@example.com>
Date:   Fri Feb 20 06:59:02 2026 -0500

    docs(user-guide): add v6 Scenario Intelligence section
    
    - New section "v6 Scenario Intelligence - Ask Nereus Forward-Looking Queries"
      covering all 6 scenario types with example questions and example responses
    - Engine reference table linking each engine to its source file and DOI
    - Validation anchor callout (Cabo Pulmo -$20.16M, BCR 13.34, VaR_95 $646.6M)
    - Updated precomputed response count 73 -> 139 and query categories 6 -> 7
    - Updated sidebar metadata: axiom count 35 -> 40
    
    Co-Authored-By: Claude Sonnet 4.6 <noreply@anthropic.com>

diff --git a/docs/user_guide.md b/docs/user_guide.md
index 3ffad44..befe316 100644
--- a/docs/user_guide.md
+++ b/docs/user_guide.md
@@ -140,7 +140,7 @@ TNFD LEAP disclosure generation and alignment scoring for all 9 sites:
 - **Service health panel** - Shows API, Neo4j, and LLM connectivity status (Live mode only)
 - **Site selector** - All 9 Gold-tier sites available
 - **Scenario slider** - Conservative (P5) / Base Case (Median) / Optimistic (P95)
-- **System metadata** - Schema version, site count (9), bridge axiom count (35)
+- **System metadata** - Schema version, site count (9), bridge axiom count (40)
 
 ### v3 Intelligence Platform
 
@@ -250,7 +250,7 @@ Valuation and provenance queries for any of these sites return rich, multi-layer
 
 **Comparison sites** (Great Barrier Reef, Papahanaumokuakea) have governance metadata (NEOLI score, area, asset rating) but not full ecosystem service valuations. Queries about their financial value will note the absence of site-specific valuation data.
 
-When the API is unavailable, Ask Nereus falls back to 73+ precomputed responses covering all 6 query categories (valuation, provenance, axiom, comparison, risk, concept_explanation). The fallback uses TF-IDF-style keyword matching to find the best precomputed answer for your question.
+When the API is unavailable, Ask Nereus falls back to 139 precomputed responses covering all 7 query categories (valuation, provenance, axiom, comparison, risk, concept_explanation, scenario_analysis). The fallback uses TF-IDF-style keyword matching to find the best precomputed answer for your question.
 
 ### Graph Explorer
 
@@ -266,6 +266,78 @@ Edges show provenance relationships: GENERATES (MPA -> service), TRANSLATES (axi
 
 ---
 
+## v6 Scenario Intelligence - Ask Nereus Forward-Looking Queries
+
+v6 adds a seventh query category - `scenario_analysis` - to the Ask Nereus engine. Scenario queries are automatically detected, parsed into structured `ScenarioRequest` objects, routed to the appropriate computation engine, and returned with P5/P50/P95 uncertainty envelopes and full provenance.
+
+### Scenario Query Types
+
+| Type | Description | Example Question |
+|------|-------------|-----------------|
+| **Counterfactual** | ESV delta if protection were removed | "What would Cabo Pulmo be worth without protection?" |
+| **Climate / SSP** | Habitat degradation under SSP1-2.6, SSP2-4.5, or SSP5-8.5 | "What happens to Belize under SSP2-4.5 by 2050?" |
+| **Blue Carbon Market** | Revenue at a given carbon price ($/tCO2e) | "What blue carbon revenue could Sundarbans generate at $45/tCO2?" |
+| **Tipping Point** | McClanahan piecewise proximity to regime shift | "How close is Cabo Pulmo to a tipping point?" |
+| **Portfolio Nature VaR** | Correlated portfolio loss at P95 | "What is the portfolio nature VaR at 95th percentile?" |
+| **Intervention / ROI** | Benefit-cost ratio for a restoration investment | "What if we invest $5M to restore mangroves at Cispata?" |
+
+### Quick-Query Buttons
+
+Each site in the Scenario Lab (Tab 4) has four pre-wired quick-query buttons that fire the most common scenario question for that site. In demo mode all 36 combinations (9 sites x 4 types) are answered from precomputed responses grounded in actual Python engine output.
+
+### Example Scenario Responses
+
+**Counterfactual (Cabo Pulmo):**
+```
+Without protection, Cabo Pulmo National Park ESV would decline from $29.27M
+to an estimated $9.11M/yr - a loss of $20.16M (68.9%). The 4.63x biomass
+multiplier (Edgar et al. 2014, doi:10.1038/nature13022) collapses without
+the no-take zone, eliminating the tourism premium that accounts for $25M of
+the total. P5/P50/P95: $7.3M / $9.1M / $11.0M.
+```
+
+**Blue Carbon Market (Sundarbans at $45/tCO2e):**
+```
+Sundarbans Reserve Forest could generate ~$19.4M/yr in blue carbon revenue
+at $45/tCO2e. Calculation: 460,000 ha mangrove x 7.0 tCO2/ha/yr (Blue
+Carbon Initiative) x 0.60 Verra-verified fraction x $45 = $19,404,000/yr.
+Source: Friess et al. 2020 (doi:10.1146/annurev-environ-012220-012511).
+```
+
+**Climate / SSP (Belize under SSP2-4.5 by 2050):**
+```
+Under SSP2-4.5 by 2050, Belize Barrier Reef Reserve System ESV is projected
+to decline from $292.5M to ~$224.2M (-23.4%). Coral reef bleaching
+frequency rises from 1-in-5 years to annual under +2.0C (IPCC AR6 WG1).
+P5/P50/P95: -32% / -23% / -14%.
+```
+
+**Tipping Point (Cabo Pulmo - data available):**
+```
+Cabo Pulmo fish biomass is approximately 1,039 kg/ha - within the upper
+"Near-pristine" band of the McClanahan et al. 2011 piecewise reef function
+(threshold: 1,130 kg/ha). Tipping point proximity: 8.1% below the Near-
+pristine ceiling. Source: McClanahan et al. 2011
+(doi:10.1073/pnas.1106861108).
+```
+
+### Scientific Grounding
+
+All scenario computations are deterministically derived from the knowledge graph and case study data. The engines that power live mode are:
+
+| Engine | File | Sources |
+|--------|------|---------|
+| Counterfactual | `maris/scenario/counterfactual_engine.py` | Edgar et al. 2014 (biomass multiplier) |
+| Climate/SSP | `maris/scenario/climate_scenarios.py` | IPCC AR6, coral bleaching literature |
+| Blue Carbon | `maris/scenario/blue_carbon_revenue.py` | Blue Carbon Initiative, Friess et al. 2020 |
+| Tipping Point | `maris/scenario/tipping_point_analyzer.py` | McClanahan et al. 2011 (piecewise reef function) |
+| Stress Test | `maris/scenario/stress_test_engine.py` | Cholesky-correlated Monte Carlo (N=10,000) |
+| Real Options | `maris/scenario/real_options_valuator.py` | Black-Scholes conservation option value |
+
+Scenario responses include `axioms_used`, `propagation_trace` (step-by-step axiom chain with coefficients), `uncertainty` (P5/P50/P95), `confidence` score, and `caveats` - all surfaced in the UI. Parser validation anchors: Cabo Pulmo counterfactual delta -$20.16M, Cispata Bay BCR 13.34, Portfolio VaR_95 $646.6M (all verified against 13 invariant tests in `tests/scenario/test_scenario_invariants.py`).
+
+---
+
 ## Data Freshness Indicators
 
 The dashboard displays freshness badges next to data-dependent metrics, indicating the age of the underlying measurements:
