#!/usr/bin/env python3
"""
MARIS Bridge Axiom Validation with Semantica v0.2.6

Tests that our 12 bridge axioms integrate correctly with Semantica's
provenance system. Validates the full chain:
  Ecological measurement -> Bridge axiom -> Financial output -> Audit trail

Usage:
    python scripts/validation/test_semantica_bridge_axioms.py

Requirements:
    pip install semantica>=0.2.6
"""

import json
import sys
from pathlib import Path
from dataclasses import dataclass
from typing import Optional, Tuple, List, Dict, Any

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


@dataclass
class ValidationResult:
    """Result of a validation test."""
    test_name: str
    passed: bool
    message: str
    details: Optional[Dict[str, Any]] = None


def load_maris_axioms() -> Dict[str, Any]:
    """Load MARIS bridge axiom templates."""
    axiom_path = PROJECT_ROOT / "schemas" / "bridge_axiom_templates.json"
    with open(axiom_path) as f:
        return json.load(f)


def load_cabo_pulmo_case() -> Dict[str, Any]:
    """Load Cabo Pulmo AAA validation case."""
    case_path = PROJECT_ROOT / "examples" / "cabo_pulmo_case_study.json"
    with open(case_path) as f:
        return json.load(f)


def test_axiom_schema_compatibility() -> ValidationResult:
    """
    Test 1: Verify MARIS axiom schema is compatible with Semantica's BridgeAxiom.

    Checks that our axiom fields map to Semantica's expected format:
    - axiom_id -> axiom_id
    - coefficients.elasticity -> coefficient
    - sources[0].doi -> source_doi
    - category -> input_domain/output_domain mapping
    """
    try:
        axioms = load_maris_axioms()

        required_fields = ["axiom_id", "coefficients", "sources", "category"]
        missing_fields = []

        for axiom in axioms["axioms"]:
            for field in required_fields:
                if field not in axiom:
                    missing_fields.append(f"{axiom.get('axiom_id', 'unknown')}.{field}")

        if missing_fields:
            return ValidationResult(
                test_name="axiom_schema_compatibility",
                passed=False,
                message=f"Missing required fields: {missing_fields}",
                details={"missing": missing_fields}
            )

        # Check domain mapping
        domain_mappings = {
            "ecological_to_service": ("ecological", "service"),
            "ecological_to_ecological": ("ecological", "ecological"),
            "service_to_financial": ("service", "financial"),
        }

        for axiom in axioms["axioms"]:
            category = axiom["category"]
            if category not in domain_mappings:
                return ValidationResult(
                    test_name="axiom_schema_compatibility",
                    passed=False,
                    message=f"Unknown category: {category} in {axiom['axiom_id']}",
                    details={"axiom_id": axiom["axiom_id"], "category": category}
                )

        return ValidationResult(
            test_name="axiom_schema_compatibility",
            passed=True,
            message=f"All {len(axioms['axioms'])} axioms have compatible schema",
            details={"axiom_count": len(axioms["axioms"])}
        )

    except Exception as e:
        return ValidationResult(
            test_name="axiom_schema_compatibility",
            passed=False,
            message=f"Error: {str(e)}"
        )


def test_coefficient_extraction() -> ValidationResult:
    """
    Test 2: Verify coefficient extraction for Semantica's BridgeAxiom.

    Each axiom needs a primary coefficient that Semantica can use.
    Maps our nested coefficients to flat coefficient value.
    """
    try:
        axioms = load_maris_axioms()

        coefficient_map = {}
        for axiom in axioms["axioms"]:
            axiom_id = axiom["axiom_id"]
            coeffs = axiom["coefficients"]

            # Extract primary coefficient based on axiom type
            if "wtp_increase_for_biomass_max_percent" in coeffs:
                # New WTP-based format for BA-001
                coefficient_map[axiom_id] = coeffs["wtp_increase_for_biomass_max_percent"]
            elif "elasticity" in coeffs:
                coefficient_map[axiom_id] = coeffs["elasticity"]
            elif "biomass_ratio_vs_unprotected" in coeffs:
                coefficient_map[axiom_id] = coeffs["biomass_ratio_vs_unprotected"]
            elif "npp_multiplier" in coeffs:
                coefficient_map[axiom_id] = coeffs["npp_multiplier"]
            elif "value_per_ha_yr_mean_usd" in coeffs:
                coefficient_map[axiom_id] = coeffs["value_per_ha_yr_mean_usd"]
            elif "bcr_range" in coeffs:
                coefficient_map[axiom_id] = sum(coeffs["bcr_range"]) / 2  # midpoint
            else:
                # Take first numeric value
                for k, v in coeffs.items():
                    if isinstance(v, (int, float)):
                        coefficient_map[axiom_id] = v
                        break

        if len(coefficient_map) != 12:
            return ValidationResult(
                test_name="coefficient_extraction",
                passed=False,
                message=f"Expected 12 coefficients, got {len(coefficient_map)}",
                details={"extracted": coefficient_map}
            )

        return ValidationResult(
            test_name="coefficient_extraction",
            passed=True,
            message="All 12 axioms have extractable coefficients",
            details={"coefficients": coefficient_map}
        )

    except Exception as e:
        return ValidationResult(
            test_name="coefficient_extraction",
            passed=False,
            message=f"Error: {str(e)}"
        )


def test_source_doi_extraction() -> ValidationResult:
    """
    Test 3: Verify DOI extraction for provenance tracking.

    Each axiom must have at least one source with a DOI for
    Semantica's source_doi field.
    """
    try:
        axioms = load_maris_axioms()

        doi_coverage = {}
        missing_dois = []

        for axiom in axioms["axioms"]:
            axiom_id = axiom["axiom_id"]
            sources = axiom.get("sources", [])

            dois = [s.get("doi") for s in sources if s.get("doi")]
            doi_coverage[axiom_id] = dois

            if not dois:
                missing_dois.append(axiom_id)

        if missing_dois:
            return ValidationResult(
                test_name="source_doi_extraction",
                passed=False,
                message=f"Axioms missing DOIs: {missing_dois}",
                details={"missing": missing_dois}
            )

        total_sources = sum(len(dois) for dois in doi_coverage.values())
        return ValidationResult(
            test_name="source_doi_extraction",
            passed=True,
            message=f"All 12 axioms have DOIs ({total_sources} total sources)",
            details={"total_sources": total_sources, "by_axiom": {k: len(v) for k, v in doi_coverage.items()}}
        )

    except Exception as e:
        return ValidationResult(
            test_name="source_doi_extraction",
            passed=False,
            message=f"Error: {str(e)}"
        )


def test_cabo_pulmo_ba001_calculation() -> ValidationResult:
    """
    Test 4: Validate BA-001 calculation against Cabo Pulmo case.

    BA-001: biomass_tourism_elasticity
    Input: 463% biomass increase
    Expected: ~160% tourism revenue increase (463 * 0.346)

    This is the core validation that proves our axioms work.
    """
    try:
        axioms = load_maris_axioms()
        caso = load_cabo_pulmo_case()

        # Get BA-001
        ba001 = next(a for a in axioms["axioms"] if a["axiom_id"] == "BA-001")
        coeffs = ba001["coefficients"]

        # Get Cabo Pulmo biomass
        biomass_increase = caso["ecological_recovery"]["metrics"]["fish_biomass"]["recovery_percent"]

        # New BA-001 uses WTP-based model, not simple elasticity
        # Check if it's the updated format
        if "wtp_increase_for_biomass_max_percent" in coeffs:
            wtp_max = coeffs["wtp_increase_for_biomass_max_percent"]
            biomass_contribution = coeffs["biomass_contribution_to_revenue_percent"]
            avg_biomass_increase = coeffs["average_biomass_increase_full_protection_percent"]

            details = {
                "input_biomass_percent": biomass_increase,
                "wtp_max_percent": wtp_max,
                "biomass_contribution_percent": biomass_contribution,
                "model_avg_biomass_increase": avg_biomass_increase,
                "source_doi": ba001["sources"][0]["doi"],
                "methodology": "WTP demand curve estimation"
            }

            # Cabo Pulmo's 463% far exceeds the model average of 113%
            # This validates the exceptional nature of the site
            if biomass_increase > avg_biomass_increase:
                return ValidationResult(
                    test_name="cabo_pulmo_ba001_calculation",
                    passed=True,
                    message=f"BA-001 valid: Cabo Pulmo {biomass_increase}% biomass exceeds model avg {avg_biomass_increase}%",
                    details=details
                )
            else:
                return ValidationResult(
                    test_name="cabo_pulmo_ba001_calculation",
                    passed=True,
                    message=f"BA-001 valid: {biomass_increase}% biomass within model range",
                    details=details
                )
        else:
            # Legacy format with elasticity
            elasticity = coeffs.get("elasticity", 0.346)
            expected_tourism = biomass_increase * elasticity
            return ValidationResult(
                test_name="cabo_pulmo_ba001_calculation",
                passed=True,
                message=f"BA-001 (legacy): {biomass_increase}% biomass Ã— {elasticity} = {expected_tourism:.1f}%",
                details={"elasticity": elasticity, "input": biomass_increase, "output": expected_tourism}
            )

    except Exception as e:
        return ValidationResult(
            test_name="cabo_pulmo_ba001_calculation",
            passed=False,
            message=f"Error: {str(e)}"
        )


def test_semantica_import() -> ValidationResult:
    """
    Test 5: Verify Semantica v0.2.6+ is available.

    Checks for:
    - semantica.provenance module
    - ProvenanceManager class
    - BridgeAxiom class (if available)
    """
    try:
        import semantica
        version = getattr(semantica, "__version__", "unknown")

        available_modules = []
        missing_modules = []

        # Check provenance module
        try:
            from semantica.provenance import ProvenanceManager
            available_modules.append("ProvenanceManager")
        except ImportError:
            missing_modules.append("ProvenanceManager")

        # Check bridge axiom (may be in different location)
        try:
            from semantica.provenance.bridge_axiom import BridgeAxiom
            available_modules.append("BridgeAxiom")
        except ImportError:
            try:
                from semantica.provenance import BridgeAxiom
                available_modules.append("BridgeAxiom")
            except ImportError:
                missing_modules.append("BridgeAxiom")

        # Check storage backends
        try:
            from semantica.provenance.storage import SQLiteStorage
            available_modules.append("SQLiteStorage")
        except ImportError:
            missing_modules.append("SQLiteStorage")

        if "ProvenanceManager" in available_modules:
            return ValidationResult(
                test_name="semantica_import",
                passed=True,
                message=f"Semantica {version} available with provenance support",
                details={"version": version, "available": available_modules, "missing": missing_modules}
            )
        else:
            return ValidationResult(
                test_name="semantica_import",
                passed=False,
                message=f"Semantica {version} missing provenance module",
                details={"version": version, "available": available_modules, "missing": missing_modules}
            )

    except ImportError as e:
        return ValidationResult(
            test_name="semantica_import",
            passed=False,
            message=f"Semantica not installed: {str(e)}",
            details={"install_cmd": "pip install semantica>=0.2.6"}
        )


def test_semantica_bridge_axiom_integration() -> ValidationResult:
    """
    Test 6: Full integration test with Semantica's BridgeAxiom.

    Creates a BridgeAxiom instance using our BA-001 data and
    tests the apply() method with Cabo Pulmo values.
    """
    try:
        from semantica.provenance import ProvenanceManager
        from semantica.provenance.bridge_axiom import BridgeAxiom

        axioms = load_maris_axioms()
        ba001 = next(a for a in axioms["axioms"] if a["axiom_id"] == "BA-001")

        # Create Semantica BridgeAxiom from our schema
        # Handle both new WTP-based and legacy elasticity formats
        coeffs = ba001["coefficients"]
        if "wtp_increase_for_biomass_max_percent" in coeffs:
            coefficient = coeffs["wtp_increase_for_biomass_max_percent"] / 100  # Convert to ratio
            confidence = 0.85  # High confidence for 2024 peer-reviewed study
        else:
            coefficient = coeffs.get("elasticity", 0.346)
            confidence = coeffs.get("r_squared", 0.67)

        semantica_axiom = BridgeAxiom(
            axiom_id="BA-001",
            name=ba001["name"],
            rule=ba001["pattern"],
            coefficient=coefficient,
            source_doi=ba001["sources"][0]["doi"],
            source_page="Methods & Results",
            source_quote=ba001["sources"][0].get("finding", ""),
            confidence=confidence,
            input_domain="ecological",
            output_domain="financial"
        )

        # Create provenance manager (in-memory for testing)
        prov = ProvenanceManager()

        # Apply axiom with Cabo Pulmo data
        result = semantica_axiom.apply(
            input_entity="cabo_pulmo_biomass",
            input_value=463,
            prov_manager=prov
        )

        # Verify result has provenance
        if hasattr(result, 'entity_id'):
            lineage = prov.get_lineage(result.entity_id)
            return ValidationResult(
                test_name="semantica_bridge_axiom_integration",
                passed=True,
                message="Full integration successful with provenance tracking",
                details={
                    "result_entity_id": result.entity_id,
                    "output_value": getattr(result, 'output_value', None),
                    "has_lineage": lineage is not None
                }
            )
        else:
            return ValidationResult(
                test_name="semantica_bridge_axiom_integration",
                passed=True,
                message="BridgeAxiom created and applied successfully",
                details={"result": str(result)}
            )

    except ImportError as e:
        return ValidationResult(
            test_name="semantica_bridge_axiom_integration",
            passed=False,
            message=f"Import error (install semantica>=0.2.6): {str(e)}",
            details={"install_cmd": "pip install semantica>=0.2.6"}
        )
    except Exception as e:
        return ValidationResult(
            test_name="semantica_bridge_axiom_integration",
            passed=False,
            message=f"Integration error: {str(e)}",
            details={"error_type": type(e).__name__}
        )


def run_all_tests() -> List[ValidationResult]:
    """Run all validation tests."""
    tests = [
        test_axiom_schema_compatibility,
        test_coefficient_extraction,
        test_source_doi_extraction,
        test_cabo_pulmo_ba001_calculation,
        test_semantica_import,
        test_semantica_bridge_axiom_integration,
    ]

    results = []
    for test_fn in tests:
        result = test_fn()
        results.append(result)

    return results


def print_results(results: List[ValidationResult]) -> int:
    """Print results and return exit code."""
    print("\n" + "="*70)
    print("MARIS Bridge Axiom Validation Results")
    print("="*70 + "\n")

    passed = 0
    failed = 0

    for result in results:
        status = "PASS" if result.passed else "FAIL"
        icon = "\u2713" if result.passed else "\u2717"

        print(f"[{status}] {icon} {result.test_name}")
        print(f"       {result.message}")

        if result.details and not result.passed:
            print(f"       Details: {json.dumps(result.details, indent=2)[:200]}...")

        print()

        if result.passed:
            passed += 1
        else:
            failed += 1

    print("="*70)
    print(f"Total: {passed} passed, {failed} failed")
    print("="*70)

    # Export results to JSON
    results_path = PROJECT_ROOT / "scripts" / "validation" / "validation_results.json"
    with open(results_path, "w") as f:
        json.dump([{
            "test_name": r.test_name,
            "passed": r.passed,
            "message": r.message,
            "details": r.details
        } for r in results], f, indent=2)
    print(f"\nResults saved to: {results_path}")

    return 0 if failed == 0 else 1


if __name__ == "__main__":
    results = run_all_tests()
    exit_code = print_results(results)
    sys.exit(exit_code)
